from search_subsidy import search_subsidy_urls_detailed_prefecture
import os

def test_prefecture_search():
    """search_subsidy_urls_detailed_prefectureé–¢æ•°ã®ãƒ†ã‚¹ãƒˆ"""

    print("ğŸ” ãƒ†ã‚¹ãƒˆé–‹å§‹: search_subsidy_urls_detailed_prefecture")

    # ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®éƒ½é“åºœçœŒ
    prefecture = "åƒè‘‰çœŒ"

    print(f"ãƒ†ã‚¹ãƒˆå¯¾è±¡: {prefecture}")
    print("âš ï¸  ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰: æœ€åˆã®2ã¤ã®å¸‚åŒºç”ºæ‘ã®ã¿å‡¦ç†")

    # limit_citiesã‚’ä½¿ã£ã¦ãƒ†ã‚¹ãƒˆï¼ˆAPIã‚³ã‚¹ãƒˆã‚’æŠ‘ãˆã‚‹ãŸã‚ï¼‰
    result = search_subsidy_urls_detailed_prefecture(
        prefecture=prefecture,
        max_results=20,  # å„ã‚¯ã‚¨ãƒªã®çµæœæ•°ã‚’åˆ¶é™
        save_files=True,
        limit_cities=None  # æœ€åˆã®2ã¤ã®å¸‚åŒºç”ºæ‘ã®ã¿
    )

    print("\nğŸ“Š çµæœã‚µãƒãƒªãƒ¼:")
    print(f"å‡¦ç†å¸‚åŒºç”ºæ‘æ•°: {len(result)}")

    total_urls = 0
    cities_with_results = 0

    for city, data in result.items():
        city_url_count = sum(q["URLæ•°"] for q in data if q["status"] == "success")
        total_urls += city_url_count
        if city_url_count > 0:
            cities_with_results += 1

        print(f"  ğŸ˜ï¸ {city}: {city_url_count}ä»¶ã®URL")

        # å„ã‚¯ã‚¨ãƒªã®è©³ç´°ã‚‚è¡¨ç¤º
        for i, query_data in enumerate(data):
            status_icon = "âœ…" if query_data["status"] == "success" else "âŒ"
            print(f"    {status_icon} ã‚¯ã‚¨ãƒª{i+1}: {query_data['URLæ•°']}ä»¶")

    print(f"\nğŸ“ˆ çµ±è¨ˆ:")
    print(f"  ç·URLæ•°: {total_urls}")
    print(f"  çµæœãŒã‚ã£ãŸå¸‚åŒºç”ºæ‘: {cities_with_results}/{len(result)}")

    # ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
    expected_files = [
        f"{prefecture}_subsidy_urls_detailed.json",
        f"{prefecture}_all_urls.txt",
        f"{prefecture}_stats.json",
        f"{prefecture}_search_results_detailed.csv"
    ]

    print(f"\nğŸ“ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª:")
    file_descriptions = {
        f"{prefecture}_subsidy_urls_detailed.json": "è©³ç´°æ¤œç´¢çµæœï¼ˆæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ï¼‰",
        f"{prefecture}_all_urls.txt": "å…¨URLä¸€è¦§ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ãƒªã‚¹ãƒˆï¼‰",
        f"{prefecture}_stats.json": "çµ±è¨ˆæƒ…å ±",
        f"{prefecture}_search_results_detailed.csv": "æ¤œç´¢çµæœè©³ç´°CSVï¼ˆéƒ½é“åºœçœŒã€å¸‚åŒºç”ºæ‘ã€ã‚¯ã‚¨ãƒªã€URLï¼‰"
    }

    for filename in expected_files:
        if os.path.exists(filename):
            file_size = os.path.getsize(filename)
            description = file_descriptions.get(filename, "")
            print(f"  âœ… {filename} ({file_size} bytes) - {description}")
        else:
            description = file_descriptions.get(filename, "")
            print(f"  âŒ {filename} (è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“) - {description}")

    print("\nğŸ“Š æ–°æ©Ÿèƒ½:")
    print("  ãƒ»æ¤œç´¢çµæœè©³ç´°CSV: å„ã‚¯ã‚¨ãƒªã§å–å¾—ã—ãŸURLã‚’ã‚·ãƒ³ãƒ—ãƒ«ã«ä¸€è¦§è¡¨ç¤º")
    print("  ãƒ»ã‚«ãƒ©ãƒ : éƒ½é“åºœçœŒã€å¸‚åŒºç”ºæ‘ã€ã‚¯ã‚¨ãƒªã€URL")
    print("\nâœ… ãƒ†ã‚¹ãƒˆå®Œäº†!")

if __name__ == '__main__':
    test_prefecture_search()