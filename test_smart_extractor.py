#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
é«˜ç²¾åº¦URLæŠ½å‡ºæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import json
from smart_url_extractor import extract_urls_with_openai, extract_urls_with_beautifulsoup_improved, compare_extraction_methods
from html_fetcher import fetch_html

def test_extraction_methods():
    """
    æŠ½å‡ºæ–¹æ³•ã®ãƒ†ã‚¹ãƒˆ
    """
    print("ğŸ§ª URLæŠ½å‡ºç²¾åº¦ãƒ†ã‚¹ãƒˆ")
    print("-" * 50)

    # ãƒ†ã‚¹ãƒˆç”¨URLï¼ˆæ‰‹å‹•ã§å…¥åŠ›ï¼‰
    test_url = input("ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®URLï¼ˆä¸€è¦§ãƒšãƒ¼ã‚¸ï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ").strip()

    if not test_url:
        print("âŒ URLãŒå…¥åŠ›ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        return

    try:
        # HTMLã‚’å–å¾—
        print(f"ğŸ“¥ HTMLã‚’å–å¾—ä¸­: {test_url}")
        html_path = fetch_html(test_url, "test_extraction.html")

        with open(html_path, 'r', encoding='utf-8') as f:
            html_content = f.read()

        # ä¸¡æ–¹ã®æ–¹æ³•ã§æŠ½å‡ºãƒ»æ¯”è¼ƒ
        print("\nğŸ” æŠ½å‡ºæ–¹æ³•ã‚’æ¯”è¼ƒä¸­...")
        comparison = compare_extraction_methods(html_content, test_url)

        # çµæœã‚’è¡¨ç¤º
        print(f"\n{'='*60}")
        print(f"ğŸ“Š æŠ½å‡ºçµæœæ¯”è¼ƒ")
        print(f"{'='*60}")

        print(f"ğŸ¤– OpenAI API: {comparison['openai_count']}ä»¶")
        print(f"ğŸ” BeautifulSoupæ”¹è‰¯ç‰ˆ: {comparison['beautifulsoup_count']}ä»¶")
        print(f"ğŸ¤ å…±é€š: {len(comparison['common_urls'])}ä»¶")
        print(f"ğŸ†• OpenAIç‹¬è‡ª: {len(comparison['openai_only'])}ä»¶")
        print(f"ğŸ†• BeautifulSoupç‹¬è‡ª: {len(comparison['beautifulsoup_only'])}ä»¶")

        # è©³ç´°çµæœã‚’è¡¨ç¤º
        print(f"\n--- OpenAIçµæœã®è©³ç´° ---")
        for i, url_info in enumerate(comparison['openai_result']['subsidy_related_urls'][:5], 1):
            print(f"{i}. {url_info['link_text'][:30]} (ã‚¹ã‚³ã‚¢: {url_info['relevance_score']:.2f})")
            print(f"   URL: {url_info['url'][:80]}...")
            print(f"   ç†ç”±: {url_info['reasoning']}")

        if len(comparison['openai_result']['subsidy_related_urls']) > 5:
            print(f"   ... ä»–{len(comparison['openai_result']['subsidy_related_urls']) - 5}ä»¶")

        print(f"\n--- BeautifulSoupæ”¹è‰¯ç‰ˆã®è©³ç´° ---")
        for i, url_info in enumerate(comparison['beautifulsoup_result']['subsidy_related_urls'][:5], 1):
            print(f"{i}. {url_info['link_text'][:30]} (ã‚¹ã‚³ã‚¢: {url_info['relevance_score']:.2f})")
            print(f"   URL: {url_info['url'][:80]}...")
            print(f"   ç†ç”±: {url_info['reasoning']}")

        if len(comparison['beautifulsoup_result']['subsidy_related_urls']) > 5:
            print(f"   ... ä»–{len(comparison['beautifulsoup_result']['subsidy_related_urls']) - 5}ä»¶")

        # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with open('extraction_comparison_test.json', 'w', encoding='utf-8') as f:
            json.dump(comparison, f, ensure_ascii=False, indent=2)
        print(f"\nâœ… è©³ç´°ãªæ¯”è¼ƒçµæœã‚’ä¿å­˜: extraction_comparison_test.json")

    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")

def main():
    """
    ãƒ¡ã‚¤ãƒ³å‡¦ç†
    """
    print("é«˜ç²¾åº¦URLæŠ½å‡ºæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
    print("ã“ã®ãƒ„ãƒ¼ãƒ«ã¯æŠ½å‡ºç²¾åº¦ã®é•ã„ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã®ã‚‚ã®ã§ã™ã€‚")
    print("å®Ÿéš›ã®ä¸€è¦§ãƒšãƒ¼ã‚¸URLã‚’å…¥åŠ›ã—ã¦ã€æŠ½å‡ºçµæœã‚’æ¯”è¼ƒã§ãã¾ã™ã€‚")
    print()

    test_extraction_methods()

if __name__ == '__main__':
    main()
